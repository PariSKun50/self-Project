# -*- coding: utf-8 -*-
"""Submit q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iO6GUP5Ma6jCjAfQZhyIGkeSxJzmZJbi

# **Answer 3**

# Step 1 : Cloning and Navigating to the PyTorch UNet Repository
"""

!ls

"""##### Cloning a Git repository named "pytorch-unet"
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/usuyama/pytorch-unet.git
# %cd pytorch-unet

import os

# Get the current working directory
current_path = os.getcwd()

# Print the current working directory
print("Current working directory:", current_path)

"""# Step 2 : Importing pathology images dataset from github"""

!git clone https://github.com/Term5Assignment/AAI_GoogleCollab

!ls

#Checking for contents of the folder
!ls AAI_GoogleCollab/pathologyData

#Passing folder path of train and test to the variables
train_data_dir = 'AAI_GoogleCollab/pathologyData/train'
test_data_dir = 'AAI_GoogleCollab/pathologyData/test'

"""# Step 3 : Importing necessary libraries"""

import torchvision
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
from torch import optim
import cv2, glob, numpy as np, pandas as pd
import matplotlib.pyplot as plt
from glob import glob
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import os
import torch
from torchvision import models, transforms
from torchvision.io import read_image
from sklearn.metrics import accuracy_score
import pytorch_unet

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

"""# Step 4 : Checking for contents of Train and Test folders

#### Checking for contents of the train and test folder in the pathology dataset
"""

import os

folder = 'AAI_GoogleCollab/pathologyData/'

# Check if the folder exists
if os.path.exists(folder):
    print("Sub-folders in the first folder '{}':".format(os.listdir(folder)[0]))
    print(os.listdir(os.path.join(folder, os.listdir(folder)[0])))
    print("Sub-folders in the first folder '{}':".format(os.listdir(folder)[1]))
    print(os.listdir(os.path.join(folder, os.listdir(folder)[1])))
else:
    print(f"The folder '{folder}' does not exist.")

"""#### Checking for number of items into the each folder"""

# Checking for number of items in each of the folder
folder = "AAI_GoogleCollab/pathologyData/"

# List all subfolders in the main folder
subfolders = os.listdir(folder)

# Iterate through each subfolder
for subfolder in subfolders:
    subfolder_path = os.path.join(folder, subfolder)

    # Check if the item is a subfolder
    if os.path.isdir(subfolder_path):
        # Count the number of items in the subfolder
        num_items = len(os.listdir(subfolder_path))

        # Print the result
        print("Number of items in subfolder '{}': {}".format(subfolder, num_items))

"""##### Number of items in subfolder 'train': 120 inclusive of both 60 Sample and 60 Masks of the sample (.tif and .png)
##### Number of items in subfolder 'test': 48 inclusive of both 24 Sample and 24 Masks of the sample (.tif and .png)
Where mask is like a class label

#### Checking for device which we are working on
"""

# Checking for the device on which we are going to work
if not torch.cuda.is_available():
  raise Exception("GPU not availalbe. CPU training will be too slow.")
print("device name", torch.cuda.get_device_name(0))

"""#### Checking for the sample image from the trainset"""

from PIL import Image
image=Image.open('AAI_GoogleCollab/pathologyData/train/10256_500_f00001_original.tif')

image

"""### Reading and Storing .tif Images as Arrays in a Specified Folder (tif_files)
Sample images
"""

from PIL import Image
import os
import numpy as np

folder_path = 'AAI_GoogleCollab/pathologyData/train/'
file_type = 'tif'

# Get a list of all files in the folder with the specified file type
tif_files = sorted([file for file in os.listdir(folder_path) if file.endswith(f".{file_type}")])

# Read each ".tif" file and store as an array
image_arrays = []

for tif_file in tif_files:
    file_path = os.path.join(folder_path, tif_file)
    img = Image.open(file_path)
    img_array = np.array(img)
    image_arrays.append(img_array)

#Listing all sample files
tif_files

"""#### Checking for mask image from the train set"""

mask = Image.open('AAI_GoogleCollab/pathologyData/train/10256_500_f00001_original.out.png')
mask

"""### Reading and Storing png Images as Arrays in a Specified Folder (png_files)"""

from PIL import Image
import os
import numpy as np

folder_path = 'AAI_GoogleCollab/pathologyData/train/'
png_files = sorted([file for file in os.listdir(folder_path) if file.endswith('.png')])

# Read each ".png" file and store as an array
png_arrays = []

for png_file in png_files:
    file_path = os.path.join(folder_path, png_file)
    img = Image.open(file_path)
    img_array = np.array(img)
    png_arrays.append(img_array)

#Listing all masks files
png_files

"""### Left: Input image (Coloured), Right: Target mask (2Class)
Original images
"""

import helper
helper.plot_side_by_side([image_arrays, png_arrays])

"""# Step 5 : Prepare Dataset and DataLoader

### Data Preparation for Nuclei Segmentation with PyTorch

The code below defines a PyTorch Dataset class, 'NucleiDataset',
For nuclei segmentation tasks of Pathology images which are given.
It prepares the data by applying transformations to both the input images and their corresponding masks.
The dataset is then loaded into PyTorch DataLoader for training and testing.

Comments:
1. Import necessary libraries.
2. Define file paths for training and testing data.
3. Create the 'NucleiDataset' class for handling the dataset.
4. Define transformations for both images and masks.
5. Example usage of the dataset with DataLoader for training and testing.
6. Define a function 'reverse_transform' for reversing image transformations.
7. Define a function 'reverse_transform_grayscale' for reversing grayscale mask transformations.
8. Get a batch of training data and display samples.
"""

#Import necessary libraries
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import numpy as np

# Define file paths for training and testing data
folder_path_train = "AAI_GoogleCollab/pathologyData/train/"
folder_path_test = "AAI_GoogleCollab/pathologyData/test/"

# Create the 'NucleiDataset' class
class NucleiDataset(Dataset):
    def __init__(self, folder_path, image_arrays, png_arrays, transform=None):
        self.folder_path = folder_path
        self.images = image_arrays
        self.masks = png_arrays
        self.transform = transform

    def __getitem__(self, idx):
        image = self.images[idx]
        mask = self.masks[idx]

        # Apply the resizing transformation to both image and mask
        if self.transform is not None:
            image = self.transform(image)
            mask = self.transform(mask)

        return [image, mask]

    def __len__(self):
        return len(self.images)

# Using the same transformations for both image and mask
common_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(256),  # Adjust size as needed
    transforms.ToTensor(),
])

# Additional transform for the mask to ensure it has 2 channels
mask_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(256),  # Adjust size as needed
    transforms.ToTensor(),
    transforms.Lambda(lambda x: torch.cat([x, 1 - x], dim=0))  # Create a 2-channel mask
])

#Usage of the dataset
train_data_set = NucleiDataset(folder_path_train, image_arrays, png_arrays, transform=common_transform)
test_data_set = NucleiDataset(folder_path_test, image_arrays, png_arrays, transform=common_transform)

# Apply the additional mask_transform for masks
train_data_set.masks = [mask_transform(mask) for mask in train_data_set.masks]
test_data_set.masks = [mask_transform(mask) for mask in test_data_set.masks]

# Define batch size
batch_size = 2

#Create DataLoader for training and testing
dataloaders = {
    'train': DataLoader(train_data_set, batch_size=batch_size, shuffle=True, num_workers=0),
    'test': DataLoader(test_data_set, batch_size=batch_size, shuffle=True, num_workers=0)
}

# Define a function to reverse image transformations
def reverse_transform(inp):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = (std * inp) + mean
    inp = np.clip(inp, 0, 1)
    inp = (inp * 255).astype(np.uint8)
    return inp

# Define a function to reverse grayscale mask transformations
def reverse_transform_grayscale(inp):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = 0.485  # Adjust this value if needed
    std = 0.229   # Adjust this value if needed
    inp = (std * inp[:, :, 0]) + mean  # Take only the first channel for display
    inp = np.clip(inp, 0, 1)
    inp = (inp * 255).astype(np.uint8)
    return inp

# Get a batch of training data and display samples
inputs_train, masks_train = next(iter(dataloaders['train']))
print(inputs_train.shape, masks_train.shape)

# Ensuring that reverse_transform works correctly
# Display the reversed transformed images
plt.imshow(reverse_transform(inputs_train[0]))
plt.show()

# Display the reversed transformed grayscale masks
plt.imshow(reverse_transform_grayscale(masks_train[0]))
plt.show()
# helper.plot_side_by_side([image_arrays, png_arrays])

#Making sure input is converted to tensor for train dataset
train_data_set.images[0]

#Making sure input is converted to tensor for test dataset
test_data_set.images[0]

"""# Step 6 : Define the UNet model with a ResNet backbone

### Define a UNet module
#### ResNet UNet Architecture for Semantic Segmentation

This code defines a U-Net architecture for semantic segmentation using a pretrained ResNet-18 backbone. The U-Net model consists of encoder and decoder blocks to capture hierarchical features for accurate segmentation.
"""

import torch.nn as nn
import torchvision.models


def convrelu(in_channels, out_channels, kernel, padding):
  return nn.Sequential(
    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),
    nn.ReLU(inplace=True),
  )


class ResNetUNet(nn.Module):
  def __init__(self, n_class):
    super().__init__()

    # Initialize ResNet-18 as the base model
    self.base_model = torchvision.models.resnet18(pretrained=True)
    self.base_layers = list(self.base_model.children())

    # Encoder blocks
    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)
    self.layer0_1x1 = convrelu(64, 64, 1, 0)
    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)
    self.layer1_1x1 = convrelu(64, 64, 1, 0)
    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)
    self.layer2_1x1 = convrelu(128, 128, 1, 0)
    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)
    self.layer3_1x1 = convrelu(256, 256, 1, 0)
    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)
    self.layer4_1x1 = convrelu(512, 512, 1, 0)

    # Upsampling layer
    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)

    # Decoder blocks
    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)
    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)
    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)
    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)

    # Convolutional blocks for original size
    self.conv_original_size0 = convrelu(3, 64, 3, 1)
    self.conv_original_size1 = convrelu(64, 64, 3, 1)
    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)

    # Final convolutional layer
    self.conv_last = nn.Conv2d(64, n_class, 1)

 # Forward pass implementation
  def forward(self, input):
    x_original = self.conv_original_size0(input)
    x_original = self.conv_original_size1(x_original)

    layer0 = self.layer0(input)
    layer1 = self.layer1(layer0)
    layer2 = self.layer2(layer1)
    layer3 = self.layer3(layer2)
    layer4 = self.layer4(layer3)

    layer4 = self.layer4_1x1(layer4)
    x = self.upsample(layer4)
    layer3 = self.layer3_1x1(layer3)
    x = torch.cat([x, layer3], dim=1)
    x = self.conv_up3(x)

    x = self.upsample(x)
    layer2 = self.layer2_1x1(layer2)
    x = torch.cat([x, layer2], dim=1)
    x = self.conv_up2(x)

    x = self.upsample(x)
    layer1 = self.layer1_1x1(layer1)
    x = torch.cat([x, layer1], dim=1)
    x = self.conv_up1(x)

    x = self.upsample(x)
    layer0 = self.layer0_1x1(layer0)
    x = torch.cat([x, layer0], dim=1)
    x = self.conv_up0(x)

    x = self.upsample(x)
    x = torch.cat([x, x_original], dim=1)
    x = self.conv_original_size2(x)

    out = self.conv_last(x)

    return out

"""## Instantiate the UNet model

- Move the model to GPU if available
- Show model summaries
"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('device', device)
#Model Initialization

# Create an instance of the ResNetUNet model with 2 output classes segmentation.
model = ResNetUNet(2)

# Move the model to the specified device.
model = model.to(device)

#Display content of model which is initialized above
model

# Displaying a summary of the initialized model to show the architecture,
# layers, and the number of parameters in each layer.
from torchsummary import summary

# Input size: (3, 224, 224) corresponds to an RGB image with dimensions 224x224 pixels.
summary(model, input_size=(3, 224, 224))

"""# Step 7 : Define the main training loop

### Training and Evaluation Loop with Loss Calculation

##### Below code defines a training and evaluation loop for a PyTorch model using binary cross-entropy (BCE) loss
##### and Dice loss as the evaluation metric. It also includes a learning rate scheduler and saves the best model
##### Weights during training.
"""

from collections import defaultdict
import torch.nn.functional as F
from loss import dice_loss
#https://pycad.co/the-difference-between-dice-and-dice-loss/

# Setting the path to save the best model
checkpoint_path = "checkpoint.pth"
train_losses = []
test_losses = []
epochs = []

# Function to calculate the loss during training
def calc_loss(pred, target, metrics, bce_weight=0.5):
    # Binary Cross-Entropy (BCE) loss
    bce = F.binary_cross_entropy_with_logits(pred, target)

    # Applying sigmoid to predictions for Dice loss
    pred = torch.sigmoid(pred)

    # Dice loss
    dice = dice_loss(pred, target)

    # Combined loss using BCE and Dice
    loss = bce * bce_weight + dice * (1 - bce_weight)

    #Updating metrics for monitoring
    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)
    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)
    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)

    return loss

# Function to print and display metrics
def print_metrics(metrics, epoch_samples, phase):
    outputs = []
    for k in metrics.keys():
        outputs.append("{}: {:4f}".format(k, metrics[k] / epoch_samples))

    print("{}: {}".format(phase, ", ".join(outputs)))

# Training the model
def train_model(model, optimizer, scheduler, num_epochs=10):
    best_loss = 1e10   # Initialize with a large value

    # Each epoch has a training and testing phase
    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        since = time.time()

        # Each epoch has a training and testing phase
        for phase in ['train', 'test']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            metrics = defaultdict(float)
            epoch_samples = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    loss = calc_loss(outputs, labels, metrics)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                epoch_samples += inputs.size(0)

            # Print and display metrics
            print_metrics(metrics, epoch_samples, phase)
            epoch_loss = metrics['loss'] / epoch_samples

            # Adjusting learning rate during training
            if phase == 'train':
              epoch_train_loss = epoch_loss
              scheduler.step()
              for param_group in optimizer.param_groups:
                  print("LR", param_group['lr'])

            # Save the best model weights based on test loss
            if phase == 'test' and epoch_loss < best_loss:
                print(f"saving best model to {checkpoint_path}")
                best_loss = epoch_loss
                torch.save(model.state_dict(), checkpoint_path)

        time_elapsed = time.time() - since
        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
        train_losses.append(epoch_train_loss)
        test_losses.append(epoch_loss)
        epochs.append(epoch + 1)
    print('Best test loss: {:4f}'.format(best_loss))

    # Load the best model weights
    model.load_state_dict(torch.load(checkpoint_path))
    return [model,train_losses,test_losses,epochs]

"""# Step 8 : Training

#### Transfer Learning with Fine-tuning

##### Below code demonstrates transfer learning using a pre-trained ResNetUNet model for a binary classification task.
##### It freezes the backbone layers of the ResNet18 model and fine-tunes the remaining layers.
##### Using the Adam optimizer is used with a learning rate of 1e-4, and a learning rate scheduler is employed to decay the learning rate every 8 epochs by a factor of 0.1.
##### The model is trained for 25 epochs.
"""

# Importing necessary libraries
import torch
import torch.optim as optim
from torch.optim import lr_scheduler
import time

# Number of classes in the classification task
num_class = 2

# Creating an instance of the ResNetUNet model and moving it to the specified device
model = ResNetUNet(num_class).to(device)

# Freezing the backbone layers of the model
for l in model.base_layers:
  for param in l.parameters():
    param.requires_grad = False

# Using the Adam optimizer for training, only updating parameters that require gradients
optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)

#Learning rate scheduler: decays the learning rate by a factor of 0.1 every 8 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)


# Training the model using the defined train_model function for 10 epochs

model, train_losses,test_losses,epochs = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=25)

# Plotting the losses
plt.plot(epochs, train_losses, label='Training Loss')
plt.plot(epochs, test_losses, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""**Training Dynamics:**
The model's losses decrease over time, indicating learning.

**Loss Metrics:**
Both bce and dice coefficient losses decrease for training and test sets.
The model's ability to predict target masks improves on both seen and unseen data.

**Learning Rate Adjustment:**
The LR remains constant for most epochs but undergoes changes.
LR adjustments can impact the model's convergence and optimization trajectory.

**Model Saving:**
The model is saved at each epoch with a new minimum test loss.
This ensures the best-performing model is retained for later use.

**Execution Time:**
Each epoch takes approximately 5 to 7 seconds to complete.
The execution time is consistent and efficient.

**Best Test Loss:**
The best test loss is 0.275117 On 23rd Epoch.

# Step 9 : Model Evaluation & Visualization (Predict new images using the trained model)

##### Setting the model to evaluation mode and visualizing the input images, ground truth masks, and predicted masks.

##### This code snippet evaluates the trained model on a batch of test data. It sets the model to evaluation mode,obtains the first batch from the test dataloader, and performs predictions. The predicted masks, along with the input images and ground truth masks, are then visualized using matplotlib.
"""

import math

# Set model to the evaluation mode
model.eval()
model = model.to(device)

# Get the first batch of test data
inputs_test, masks_test = next(iter(dataloaders['test']))
inputs_test = inputs_test.to(device)
masks_test = masks_test.to(device)
print('inputs.shape', inputs_test.shape)
print('labels.shape', masks_test.shape)

# Predict the masks
pred = model(inputs_test)
# The loss functions include the sigmoid function.
pred = torch.sigmoid(pred)
pred = pred.data.cpu()
print('pred.shape', pred.shape)

# Convert torch tensors to numpy arrays for visualization
input_images = [reverse_transform(x) for x in inputs_test.cpu()]
masks_images = [reverse_transform_grayscale(x) for x in masks_test.cpu()]
pred_images = [reverse_transform_grayscale(x) for x in pred.cpu()]

# Display the input image
plt.imshow(input_images[0])
plt.title('Input Image')
plt.show()

# Display the ground truth mask
plt.imshow(masks_images[0])
plt.title('Label Image')
plt.show()

# Display the predicted mask
plt.imshow(pred_images[0])
plt.title('Predicted Image')
plt.show()

"""# Step 10 : Accuracy for each class

Class : Background, Foreground
"""

import math
from sklearn.metrics import confusion_matrix
# Apply a threshold to binary_pred
threshold = 0.5
binary_pred = (pred > threshold).int()

# Move masks_test to CPU
masks_test = masks_test.cpu()

# Convert masks_test to binary format (assuming it's in continuous format)
masks_test_binary = (masks_test > 0.5).int()

# Initialize metrics for each class
precision = {class_label: 0 for class_label in range(num_class)}
recall = {class_label: 0 for class_label in range(num_class)}
f1_score = {class_label: 0 for class_label in range(num_class)}

# Iterate over each class
for class_label in range(num_class):
    true_positive = ((binary_pred[:, class_label] == 1) & (masks_test[:, class_label] == 1)).sum().item()
    false_positive = ((binary_pred[:, class_label] == 1) & (masks_test[:, class_label] == 0)).sum().item()
    false_negative = ((binary_pred[:, class_label] == 0) & (masks_test[:, class_label] == 1)).sum().item()

    # Calculate precision, recall, and F1 score
    precision[class_label] = true_positive / max((true_positive + false_positive), 1)
    recall[class_label] = true_positive / max((true_positive + false_negative), 1)
    f1_score[class_label] = 2 * (precision[class_label] * recall[class_label]) / max((precision[class_label] + recall[class_label]), 1)

# Compute the overall confusion matrix
conf_matrix_norm = confusion_matrix ( masks_test_binary.view(-1).cpu(), binary_pred.view(-1).cpu(),normalize='true')
# Print or use the metrics as needed
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)

print("Overall Confusion Matrix:")
print(conf_matrix_norm)

# Defining a function to calculate accuracy per class based on a confusion matrix
def accuracy_per_class(conf_matrix):
    #Get the number of classes
    num_classes = len(conf_matrix)
    accuracies = []

    # Loop through each class
    for i in range(num_classes):
      # Extract values from the confusion matrix
        true_positives = conf_matrix[i, i]
        false_negatives = np.sum(conf_matrix[i, :]) - true_positives
        total_actual_positives = true_positives + false_negatives

        # Calculate accuracy for the current class
        if total_actual_positives == 0:
            accuracy_i = 0  # Handling the case where there are no actual positives for the class
        else:
            accuracy_i = true_positives / total_actual_positives

        # Append accuracy to the list
        accuracies.append(accuracy_i)
    # Return the list of accuracies per class
    return accuracies

# Generate a confusion matrix using actual and predicted binary masks
conf_matrix = confusion_matrix ( masks_test_binary.view(-1).cpu(), binary_pred.view(-1).cpu())

# Calculate accuracy per class using the defined function
class_accuracies = accuracy_per_class(conf_matrix)

# Print the accuracy per class
print("Accuracy per class:", class_accuracies)

print("Accuracy per class:")
for i, acc in enumerate(class_accuracies):
    print(f"Class {i}: {acc * 100:.2f}%")