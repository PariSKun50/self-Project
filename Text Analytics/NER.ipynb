{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read text file, extract sentences and words (run using Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "In 1804, after several months of profound spiritual anxiety, Jarena Lee\n",
      "moved from New Jersey to Philadelphia. There she labored as a domestic\n",
      "and worshiped among white congregations of Roman Catholics and mixed\n",
      "congregations of Methodists. On hearing an inspired sermon by the\n",
      "Reverend Richard Allen, founder of the Bethel African Methodist\n",
      "Episcopal Church, Lee joined the Methodists. She was baptized in 1807.\n",
      "Prior to her baptism, she experienced the various physical and emotional\n",
      "stages of conversion: terrifying visions of demons and eternal\n",
      "perdition; extreme feelings of ecstasy and depression; protracted\n",
      "periods of meditation, fasting, and prayer; ennui and fever; energy and\n",
      "vigor. In 1811 she married Joseph Lee, who pastored an African-American\n",
      "church in Snow Hill, New Jersey. They had six children, four of whom\n",
      "died in infancy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('bio.txt', 'r') as myfile:\n",
    "    data=myfile.read()#.replace('\\n',' ').split(\".\") #Separated the sentences \n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1804, after several months of profound spiritual anxiety, Jarena Lee\n",
      "moved from New Jersey to Philadelphia.\n",
      "\n",
      "There she labored as a domestic\n",
      "and worshiped among white congregations of Roman Catholics and mixed\n",
      "congregations of Methodists.\n",
      "\n",
      "On hearing an inspired sermon by the\n",
      "Reverend Richard Allen, founder of the Bethel African Methodist\n",
      "Episcopal Church, Lee joined the Methodists.\n",
      "\n",
      "She was baptized in 1807.\n",
      "\n",
      "Prior to her baptism, she experienced the various physical and emotional\n",
      "stages of conversion: terrifying visions of demons and eternal\n",
      "perdition; extreme feelings of ecstasy and depression; protracted\n",
      "periods of meditation, fasting, and prayer; ennui and fever; energy and\n",
      "vigor.\n",
      "\n",
      "In 1811 she married Joseph Lee, who pastored an African-American\n",
      "church in Snow Hill, New Jersey.\n",
      "\n",
      "They had six children, four of whom\n",
      "died in infancy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences = sent_tokenize(data)\n",
    "for s in sentences:\n",
    "    print(s+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', '1804', ',', 'after', 'several', 'months', 'of', 'profound', 'spiritual', 'anxiety', ',', 'Jarena', 'Lee', 'moved', 'from', 'New', 'Jersey', 'to', 'Philadelphia', '.']\n",
      "['There', 'she', 'labored', 'as', 'a', 'domestic', 'and', 'worshiped', 'among', 'white', 'congregations', 'of', 'Roman', 'Catholics', 'and', 'mixed', 'congregations', 'of', 'Methodists', '.']\n",
      "['On', 'hearing', 'an', 'inspired', 'sermon', 'by', 'the', 'Reverend', 'Richard', 'Allen', ',', 'founder', 'of', 'the', 'Bethel', 'African', 'Methodist', 'Episcopal', 'Church', ',', 'Lee', 'joined', 'the', 'Methodists', '.']\n",
      "['She', 'was', 'baptized', 'in', '1807', '.']\n",
      "['Prior', 'to', 'her', 'baptism', ',', 'she', 'experienced', 'the', 'various', 'physical', 'and', 'emotional', 'stages', 'of', 'conversion', ':', 'terrifying', 'visions', 'of', 'demons', 'and', 'eternal', 'perdition', ';', 'extreme', 'feelings', 'of', 'ecstasy', 'and', 'depression', ';', 'protracted', 'periods', 'of', 'meditation', ',', 'fasting', ',', 'and', 'prayer', ';', 'ennui', 'and', 'fever', ';', 'energy', 'and', 'vigor', '.']\n",
      "['In', '1811', 'she', 'married', 'Joseph', 'Lee', ',', 'who', 'pastored', 'an', 'African-American', 'church', 'in', 'Snow', 'Hill', ',', 'New', 'Jersey', '.']\n",
      "['They', 'had', 'six', 'children', ',', 'four', 'of', 'whom', 'died', 'in', 'infancy', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging and NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('1804', 'CD'), (',', ','), ('after', 'IN'), ('several', 'JJ'), ('months', 'NNS'), ('of', 'IN'), ('profound', 'JJ'), ('spiritual', 'JJ'), ('anxiety', 'NN'), (',', ','), ('Jarena', 'NNP'), ('Lee', 'NNP'), ('moved', 'VBD'), ('from', 'IN'), ('New', 'NNP'), ('Jersey', 'NNP'), ('to', 'TO'), ('Philadelphia', 'NNP'), ('.', '.')]\n",
      "[('There', 'EX'), ('she', 'PRP'), ('labored', 'VBD'), ('as', 'IN'), ('a', 'DT'), ('domestic', 'JJ'), ('and', 'CC'), ('worshiped', 'VBD'), ('among', 'IN'), ('white', 'JJ'), ('congregations', 'NNS'), ('of', 'IN'), ('Roman', 'NNP'), ('Catholics', 'NNPS'), ('and', 'CC'), ('mixed', 'JJ'), ('congregations', 'NNS'), ('of', 'IN'), ('Methodists', 'NNS'), ('.', '.')]\n",
      "[('On', 'IN'), ('hearing', 'VBG'), ('an', 'DT'), ('inspired', 'JJ'), ('sermon', 'NN'), ('by', 'IN'), ('the', 'DT'), ('Reverend', 'NNP'), ('Richard', 'NNP'), ('Allen', 'NNP'), (',', ','), ('founder', 'NN'), ('of', 'IN'), ('the', 'DT'), ('Bethel', 'NNP'), ('African', 'NNP'), ('Methodist', 'NNP'), ('Episcopal', 'NNP'), ('Church', 'NNP'), (',', ','), ('Lee', 'NNP'), ('joined', 'VBD'), ('the', 'DT'), ('Methodists', 'NNS'), ('.', '.')]\n",
      "[('She', 'PRP'), ('was', 'VBD'), ('baptized', 'VBN'), ('in', 'IN'), ('1807', 'CD'), ('.', '.')]\n",
      "[('Prior', 'RB'), ('to', 'TO'), ('her', 'PRP$'), ('baptism', 'NN'), (',', ','), ('she', 'PRP'), ('experienced', 'VBD'), ('the', 'DT'), ('various', 'JJ'), ('physical', 'JJ'), ('and', 'CC'), ('emotional', 'JJ'), ('stages', 'NNS'), ('of', 'IN'), ('conversion', 'NN'), (':', ':'), ('terrifying', 'JJ'), ('visions', 'NNS'), ('of', 'IN'), ('demons', 'NNS'), ('and', 'CC'), ('eternal', 'JJ'), ('perdition', 'NN'), (';', ':'), ('extreme', 'JJ'), ('feelings', 'NNS'), ('of', 'IN'), ('ecstasy', 'NN'), ('and', 'CC'), ('depression', 'NN'), (';', ':'), ('protracted', 'VBN'), ('periods', 'NNS'), ('of', 'IN'), ('meditation', 'NN'), (',', ','), ('fasting', 'NN'), (',', ','), ('and', 'CC'), ('prayer', 'NN'), (';', ':'), ('ennui', 'CC'), ('and', 'CC'), ('fever', 'NN'), (';', ':'), ('energy', 'NN'), ('and', 'CC'), ('vigor', 'NN'), ('.', '.')]\n",
      "[('In', 'IN'), ('1811', 'CD'), ('she', 'PRP'), ('married', 'VBD'), ('Joseph', 'NNP'), ('Lee', 'NNP'), (',', ','), ('who', 'WP'), ('pastored', 'VBD'), ('an', 'DT'), ('African-American', 'JJ'), ('church', 'NN'), ('in', 'IN'), ('Snow', 'NNP'), ('Hill', 'NNP'), (',', ','), ('New', 'NNP'), ('Jersey', 'NNP'), ('.', '.')]\n",
      "[('They', 'PRP'), ('had', 'VBD'), ('six', 'CD'), ('children', 'NNS'), (',', ','), ('four', 'CD'), ('of', 'IN'), ('whom', 'WP'), ('died', 'VBD'), ('in', 'IN'), ('infancy', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#Every word (token) in English is a part of speech. A part of speech is one of 36 special tag with a meaning. \n",
    "#See https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html for more understanding. \n",
    "from nltk.tag import pos_tag\n",
    "for sentence in sentences:\n",
    "    print(pos_tag(word_tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('In', 'IN'), 'S'), (('1804', 'CD'), 'S'), ((',', ','), 'S'), (('after', 'IN'), 'S'), (('several', 'JJ'), 'S'), (('months', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('profound', 'JJ'), 'S'), (('spiritual', 'JJ'), 'S'), (('anxiety', 'NN'), 'S'), ((',', ','), 'S'), (('Jarena', 'NNP'), 'PERSON'), (('Lee', 'NNP'), 'PERSON'), (('moved', 'VBD'), 'S'), (('from', 'IN'), 'S'), (('New', 'NNP'), 'GPE'), (('Jersey', 'NNP'), 'GPE'), (('to', 'TO'), 'S'), (('Philadelphia', 'NNP'), 'GSP'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('There', 'EX'), 'S'), (('she', 'PRP'), 'S'), (('labored', 'VBD'), 'S'), (('as', 'IN'), 'S'), (('a', 'DT'), 'S'), (('domestic', 'JJ'), 'S'), (('and', 'CC'), 'S'), (('worshiped', 'VBD'), 'S'), (('among', 'IN'), 'S'), (('white', 'JJ'), 'S'), (('congregations', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('Roman', 'NNP'), 'ORGANIZATION'), (('Catholics', 'NNPS'), 'ORGANIZATION'), (('and', 'CC'), 'S'), (('mixed', 'JJ'), 'S'), (('congregations', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('Methodists', 'NNS'), 'ORGANIZATION'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('On', 'IN'), 'S'), (('hearing', 'VBG'), 'S'), (('an', 'DT'), 'S'), (('inspired', 'JJ'), 'S'), (('sermon', 'NN'), 'S'), (('by', 'IN'), 'S'), (('the', 'DT'), 'S'), (('Reverend', 'NNP'), 'ORGANIZATION'), (('Richard', 'NNP'), 'PERSON'), (('Allen', 'NNP'), 'PERSON'), ((',', ','), 'S'), (('founder', 'NN'), 'S'), (('of', 'IN'), 'S'), (('the', 'DT'), 'S'), (('Bethel', 'NNP'), 'ORGANIZATION'), (('African', 'NNP'), 'ORGANIZATION'), (('Methodist', 'NNP'), 'ORGANIZATION'), (('Episcopal', 'NNP'), 'ORGANIZATION'), (('Church', 'NNP'), 'ORGANIZATION'), ((',', ','), 'S'), (('Lee', 'NNP'), 'PERSON'), (('joined', 'VBD'), 'S'), (('the', 'DT'), 'S'), (('Methodists', 'NNS'), 'ORGANIZATION'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('She', 'PRP'), 'S'), (('was', 'VBD'), 'S'), (('baptized', 'VBN'), 'S'), (('in', 'IN'), 'S'), (('1807', 'CD'), 'S'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('Prior', 'RB'), 'S'), (('to', 'TO'), 'S'), (('her', 'PRP$'), 'S'), (('baptism', 'NN'), 'S'), ((',', ','), 'S'), (('she', 'PRP'), 'S'), (('experienced', 'VBD'), 'S'), (('the', 'DT'), 'S'), (('various', 'JJ'), 'S'), (('physical', 'JJ'), 'S'), (('and', 'CC'), 'S'), (('emotional', 'JJ'), 'S'), (('stages', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('conversion', 'NN'), 'S'), ((':', ':'), 'S'), (('terrifying', 'JJ'), 'S'), (('visions', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('demons', 'NNS'), 'S'), (('and', 'CC'), 'S'), (('eternal', 'JJ'), 'S'), (('perdition', 'NN'), 'S'), ((';', ':'), 'S'), (('extreme', 'JJ'), 'S'), (('feelings', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('ecstasy', 'NN'), 'S'), (('and', 'CC'), 'S'), (('depression', 'NN'), 'S'), ((';', ':'), 'S'), (('protracted', 'VBN'), 'S'), (('periods', 'NNS'), 'S'), (('of', 'IN'), 'S'), (('meditation', 'NN'), 'S'), ((',', ','), 'S'), (('fasting', 'NN'), 'S'), ((',', ','), 'S'), (('and', 'CC'), 'S'), (('prayer', 'NN'), 'S'), ((';', ':'), 'S'), (('ennui', 'CC'), 'S'), (('and', 'CC'), 'S'), (('fever', 'NN'), 'S'), ((';', ':'), 'S'), (('energy', 'NN'), 'S'), (('and', 'CC'), 'S'), (('vigor', 'NN'), 'S'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('In', 'IN'), 'S'), (('1811', 'CD'), 'S'), (('she', 'PRP'), 'S'), (('married', 'VBD'), 'S'), (('Joseph', 'NNP'), 'PERSON'), (('Lee', 'NNP'), 'PERSON'), ((',', ','), 'S'), (('who', 'WP'), 'S'), (('pastored', 'VBD'), 'S'), (('an', 'DT'), 'S'), (('African-American', 'JJ'), 'S'), (('church', 'NN'), 'S'), (('in', 'IN'), 'S'), (('Snow', 'NNP'), 'GPE'), (('Hill', 'NNP'), 'GPE'), ((',', ','), 'S'), (('New', 'NNP'), 'GPE'), (('Jersey', 'NNP'), 'GPE'), (('.', '.'), 'S')]\n",
      "----------\n",
      "[(('They', 'PRP'), 'S'), (('had', 'VBD'), 'S'), (('six', 'CD'), 'S'), (('children', 'NNS'), 'S'), ((',', ','), 'S'), (('four', 'CD'), 'S'), (('of', 'IN'), 'S'), (('whom', 'WP'), 'S'), (('died', 'VBD'), 'S'), (('in', 'IN'), 'S'), (('infancy', 'NN'), 'S'), (('.', '.'), 'S')]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "from nltk.chunk import ne_chunk\n",
    "#FACILITY, GPE, GSP, LOCATION, ORGANIZATION, PERSON\n",
    "#GPE is Geo-Political Entity\n",
    "#GSP is Geo-Socio-Political group\n",
    "\n",
    "for sentence in sentences:\n",
    "    entity=ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "    print(entity.pos())\n",
    "    entity.draw()\n",
    "    pos_tags = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking/NER visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S I/PRP am/VBP (PERSON Sam/NNP))\n",
      "[(('I', 'PRP'), 'S'), (('am', 'VBP'), 'S'), (('Sam', 'NNP'), 'PERSON')]\n",
      "---------------\n",
      "['Sam']\n"
     ]
    }
   ],
   "source": [
    "#Drawing entities with a full parse tree.\n",
    "\n",
    "from nltk.chunk import ne_chunk\n",
    "print(ne_chunk([('I', 'PRP'), ('am', 'VBP'), ('Sam', 'NNP')]))\n",
    "entity = ne_chunk([('I', 'PRP'), ('am', 'VBP'), ('Sam', 'NNP')])\n",
    "entity.draw()\n",
    "print(entity.pos())\n",
    "print('---------------')\n",
    "print([pos[0][0] for pos in entity.pos() if pos[1] == 'PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">But \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is starting from behind. The company made a late push</br>into hardware, and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple’s Siri\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", available on \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPhones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s Alexa</br>software, which runs on its \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Echo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dot\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " devices, have clear leads in</br>consumer adoption.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style='ent')\n",
    "\n",
    "# More examples here: https://spacy.io/usage/examples\n",
    "# 1. how to update spaCy's entity recognizer with your own examples, starting off with an existing, pre-trained model\n",
    "# 2. how to add a new entity type to an existing pre-trained NER model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get complete Person Names and Location Names from any text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jarena', 'Lee', 'Richard', 'Allen', 'Lee', 'Joseph', 'Lee']\n"
     ]
    }
   ],
   "source": [
    "#get all person names\n",
    "import nltk\n",
    "tokens = nltk.tokenize.word_tokenize(data)\n",
    "pos_tags = pos_tag(tokens)\n",
    "entities = ne_chunk(pos_tags)\n",
    "print([pos[0][0] for pos in entities.pos() if pos[1] == 'PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Jersey', 'Snow Hill', 'New Jersey']\n"
     ]
    }
   ],
   "source": [
    "#get all locations\n",
    "np_GPE = []\n",
    "for branch in entities.subtrees():\n",
    "    if branch.label() == 'GPE':\n",
    "        found_ents =  [' '.join(i[0] for i in branch.leaves())]\n",
    "        np_GPE += found_ents\n",
    "print(np_GPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Jarena Lee', 'Richard Allen', 'Lee', 'Joseph Lee'],\n",
       " ['New Jersey', 'Snow Hill', 'New Jersey'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get complete person names\n",
    "import nltk\n",
    "import time\n",
    "import nltk.tokenize\n",
    "\n",
    "def processLanguage(data):\n",
    "    data = nltk.tokenize.sent_tokenize(data)\n",
    "    np_person=[]\n",
    "    np_gpe=[]\n",
    "    for item in data:\n",
    "        tokenized = nltk.word_tokenize(item)\n",
    "        tagged = nltk.pos_tag(tokenized)\n",
    "        namedEnt = nltk.ne_chunk(tagged,binary=False)\n",
    "        found_persons = [' '.join([y[0] for y in x.leaves()]) for x in namedEnt.subtrees() if x.label() == \"PERSON\"]\n",
    "        found_gpes = [' '.join([y[0] for y in x.leaves()]) for x in namedEnt.subtrees() if x.label() == \"GPE\"]\n",
    "        np_person += found_persons\n",
    "        np_gpe += found_gpes\n",
    "        #if len(found_ents) > 0:\n",
    "        #    print(found_ents)\n",
    "    return np_person, np_gpe\n",
    "\n",
    "processLanguage(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
